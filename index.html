<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <!-- ======================================================================= -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <style type="text/css">
      body {
      font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
      font-weight:300;
      font-size:18px;
      margin-left: auto;
      margin-right: auto;
      width: 1100px;
      }
      h1 {
      font-weight:300;
      }
      .disclaimerbox {
      background-color: #eee;
      border: 1px solid #eeeeee;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
      padding: 20px;
      }
      video.header-vid {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
      }
      img.header-img {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
      }
      img.rounded {
      border: 1px solid #eeeeee;
      border-radius: 10px ;
      -moz-border-radius: 10px ;
      -webkit-border-radius: 10px ;
      }
      a:link,a:visited
      {
      color: #1367a7;
      text-decoration: none;
      }
      a:hover {
      color: #208799;
      }
      td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
      }
      .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
      0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
      5px 5px 0 0px #fff, /* The second layer */
      5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
      10px 10px 0 0px #fff, /* The third layer */
      10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
      15px 15px 0 0px #fff, /* The fourth layer */
      15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
      20px 20px 0 0px #fff, /* The fifth layer */
      20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
      25px 25px 0 0px #fff, /* The fifth layer */
      25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
      margin-left: 10px;
      margin-right: 45px;
      }
      .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
      0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
      5px 5px 0 0px #fff, /* The second layer */
      5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
      10px 10px 0 0px #fff, /* The third layer */
      10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
      margin-top: 5px;
      margin-left: 10px;
      margin-right: 30px;
      margin-bottom: 5px;
      }
      .vert-cent {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
      }
      hr
      {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
      }
      #authors td {
      padding-bottom:5px;
      padding-top:30px;
      }
    </style>
    <!-- ======================================================================= -->
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      
      gtag('config', 'UA-114291442-5');
    </script>
    <script type="text/javascript" src="./OCTraN/index_files/hidebib.js"></script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Aditya NG</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <body class="vsc-initialized">
    <br>
    <center><span style="font-size:44px;font-weight:bold;">Hi I'm Aditya NG!</span></center>
    <br>
    <!-- <table align="center" width="710px">
      <tbody>
        <tr>
          <td align="center" width="230px">
            <center><span style="font-size:22px">I build neat stuff!</span></center>
          </td>
        </tr>
        <tr>
        </tr>
        <tr>
        </tr>
      </tbody>
    </table> -->

    <table align="center" width="700px">
      <tbody>
        <tr>
          <td align="center" width="100px">
            <center><span style="font-size:28px"><a href="https://www.linkedin.com/in/adityang/">Linkedin</a></span></center>
          </td>
          <td align="center" width="100px">
            <center><span style="font-size:28px"><a href="https://github.com/AdityaNG/">Github</a></span></center>
          </td>
        </tr>
        <tr>
        </tr>
      </tbody>
    </table>
    <br>
    <hr>

    <center>
      <h2>SOccDPT</h2>
    </center>
    <table align="center" width="850px">
      <tbody>
        <tr>
          <td width="200px" align="left">
            <a href="./SOccDPT/"><img style="width:400px" src="./SOccDPT/index_files/paper_SOccDPT.png"></a>
            <center>
              <span style="font-size:20pt">
                <a href="https://arxiv.org/abs/2311.11371">[Paper]</a>
              </span>
              <span style="font-size:20pt">
                <a href="./SOccDPT/">[Project Page]</a>
              </span>
            </center>
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
            <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br><span style="font-size:6px;">&nbsp;<br></span> <span style="font-size:15pt">Aditya Nalgunda Ganesh. Soccdpt: Semi-supervised 3d semantic occupancy from dense prediction transformers trained under memory constraints. In 2024 IEEE International Conference on Robotics and Automation (ICRA), 2024. Under review.</span></p>
            <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib(&#39;octran_bib&#39;)" class="togglebib">[Bibtex]</a></span>
            <div class="paper" id="octran_bib">
              <pre xml:space="preserve" style="display: none;">@inproceedings{nalgunda2024soccdpt_bsod,
  title={SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction Transformers trained under memory constraints},
  author={Nalgunda Ganesh, Aditya},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024},
  note={Under review},
}
                </pre>
            </div>
          </td>
        </tr>
        <tr>
          <td width="250px" align="left">
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
          </td>
        </tr>
      </tbody>
    </table>
    
    <br>
    <hr>

    <center>
      <h2>OCTraN</h2>
    </center>
    <table align="center" width="850px">
      <tbody>
        <tr>
          <td width="200px" align="left">
            <a href="./OCTraN/"><img style="width:400px" src="./OCTraN/index_files/paper_OCTraN.png"></a>
            <center>
              <span style="font-size:20pt">
                <a href="https://arxiv.org/abs/2307.10934">[Paper]</a>
              </span>
              <span style="font-size:20pt">
                <a href="./OCTraN/">[Project Page]</a>
              </span>
            </center>
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
            <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br><span style="font-size:6px;">&nbsp;<br></span> <span style="font-size:15pt">Aditya N Ganesh, Dhruval Pobbathi Badrinath, Harshith Mohan Kumar, Priya S, and Surabhi Narayan. Octran: 3d occupancy convolutional transformer network in unstructured traffic scenarios. Spotlight Presentation at the Transformers for Vision Workshop, CVPR, 2023. Transformers for Vision Workshop, CVPR 2023</span></p>
            <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib(&#39;octran_bib&#39;)" class="togglebib">[Bibtex]</a></span>
            <div class="paper" id="octran_bib">
              <pre xml:space="preserve" style="display: none;">
@misc{analgund2023octran,
  title={OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios},
  author={Ganesh, Aditya N and Pobbathi Badrinath, Dhruval and
    Kumar, Harshith Mohan and S, Priya and Narayan, Surabhi
  },
  year={2023},
  howpublished={Spotlight Presentation at the Transformers for Vision Workshop, CVPR},
  url={https://sites.google.com/view/t4v-cvpr23/papers#h.enx3bt45p649},
  note={Transformers for Vision Workshop, CVPR 2023}
}
                </pre>
            </div>
          </td>
        </tr>
        <tr>
          <td width="250px" align="left">
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
          </td>
        </tr>
      </tbody>
    </table>
    
    <br>
    <hr>

    <center>
      <h2>Bengaluru Driving Dataset (OCTraN)</h2>
    </center>
    <table align="center" width="850px">
      <tbody>
        <tr>
          <td width="200px" align="left">
            <a href="./BengaluruDrivingDataset/"><img style="width:400px" src="./BengaluruDrivingDataset/index_files/BDD_Iterator_Demo-2023-08-30_08.25.17.gif"></a>
            <center>
              <span style="font-size:20pt">
                <a href="https://arxiv.org/abs/2307.10934">[Paper]</a>
              </span>
              <span style="font-size:20pt">
                <a href="./BengaluruDrivingDataset/">[Project Page]</a>
              </span>
            </center>
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
            <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br><span style="font-size:6px;">&nbsp;<br></span> <span style="font-size:15pt">Aditya N Ganesh, Dhruval Pobbathi Badrinath, Harshith Mohan Kumar, Priya S, and Surabhi Narayan. Octran: 3d occupancy convolutional transformer network in unstructured traffic scenarios. Spotlight Presentation at the Transformers for Vision Workshop, CVPR, 2023. Transformers for Vision Workshop, CVPR 2023</span></p>
            <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib(&#39;bdd_bib&#39;)" class="togglebib">[Bibtex]</a></span>
            <div class="paper" id="bdd_bib">
              <pre xml:space="preserve" style="display: none;">
@misc{analgund2023octran,
  title={OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios},
  author={Ganesh, Aditya N and Pobbathi Badrinath, Dhruval and
    Kumar, Harshith Mohan and S, Priya and Narayan, Surabhi
  },
  year={2023},
  howpublished={Spotlight Presentation at the Transformers for Vision Workshop, CVPR},
  url={https://sites.google.com/view/t4v-cvpr23/papers#h.enx3bt45p649},
  note={Transformers for Vision Workshop, CVPR 2023}
}
                </pre>
            </div>
          </td>
        </tr>
        <tr>
          <td width="250px" align="left">
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
          </td>
        </tr>
      </tbody>
    </table>
    
    <br>
    <hr>

    <center>
      <h2>Hardware-Accelerated Depth Perception</h2>
    </center>
    <table align="center" width="850px">
      <tbody>
        <tr>
          <td width="200px" align="left">
            <a href="https://www.linkedin.com/feed/update/urn:li:activity:7067379026075537408/"><img style="width:400px" src="./OCTraN/index_files/paper_stereo.png"></a>
            <center>
              <span style="font-size:20pt">
                <a href="https://link.springer.com/epdf/10.1007/978-981-19-7867-8_22?sharing_token=tGt_1kJ1-X4X_SJ7asFIhPe4RwlQNchNByi7wbcMAY7dVU38RCYC635tD8Mv0pHKLGrLXtqJR415-cGO0rTpc-m7_S8tonEWu9j7gV822VqazEY_wDsgtBGj7oTIDJbEpDvS34K3Uc75Lm_PGnmytAIfS3kvjD_LIosG273wL8E%3D">[Paper]</a>
              </span>
              <span style="font-size:20pt">
                <a href="./HardwareAcceleratedStereoVision/">[Project Page]</a>
              </span>
            </center>
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
            <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br><span style="font-size:6px;">&nbsp;<br></span> <span style="font-size:15pt">Aditya, N.G., Dhruval, P.B., Shylaja, S.S., Katharguppe, S. (2023). Low-Cost Hardware-Accelerated Vision-Based Depth Perception for Real-Time Applications. In: Tistarelli, M., Dubey, S.R., Singh, S.K., Jiang, X. (eds) Computer Vision and Machine Intelligence. Lecture Notes in Networks and Systems, vol 586. Springer, Singapore. https://doi.org/10.1007/978-981-19-7867-8_22
            </span></p>
            <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib(&#39;stereo_bib&#39;)" class="togglebib">[Bibtex]</a></span>
            <div class="paper" id="stereo_bib">
              <pre xml:space="preserve" style="display: none;">
@InProceedings{10.1007/978-981-19-7867-8_22,
  author="Aditya, N. G.
  and Dhruval, P. B.
  and Shylaja, S. S.
  and Katharguppe, Srinivas",
  editor="Tistarelli, Massimo
  and Dubey, Shiv Ram
  and Singh, Satish Kumar
  and Jiang, Xiaoyi",
  title="Low-Cost Hardware-Accelerated Vision-Based Depth Perception forÂ Real-Time Applications",
  booktitle="Computer Vision and Machine Intelligence",
  year="2023",
  publisher="Springer Nature Singapore",
  address="Singapore",
  pages="271--282",
  abstract="Depth estimation and 3D object detection are critical for autonomous systems to gain context of their surroundings. In recent times, compute capacity has improved tremendously, enabling computer vision and AI on the edge. In this paper, we harness the power of CUDA and OpenMP to accelerate ELAS (a stereoscopic vision-based disparity calculation algorithm) and 3D projection of the estimated depth while performing object detection and tracking. We also examine the utility of Bayesian inference in achieving real-time object tracking. Finally, we build a drive-by-wire car equipped with a stereo camera setup to test our system in the real world. The entire system has been made public and easily accessible through a Python module.",
  isbn="978-981-19-7867-8"
}
</pre>
            </div>
          </td>
        </tr>
        <tr>
          <td width="250px" align="left">
          </td>
          <td width="50px" align="center">
          </td>
          <td width="550px" align="left">
          </td>
        </tr>
      </tbody>
    </table>
    
    <br>
    <hr>

    <table align="center" width="800px">
      <tbody>
        <tr>
          <td width="800px">
            <left>
              <center>
                <h1>Say Hi!</h1>
              </center>
              Contact me at <a href="mailto:adityang5@gmail.com">adityang5@gmail.com</a>
              <br>
            </left>
          </td>
        </tr>
      </tbody>
    </table>
    <br><br>
    <script xml:space="preserve" language="JavaScript">
      hideallbibs();
    </script>
  </body>
</html>